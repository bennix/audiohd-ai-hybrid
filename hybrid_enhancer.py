import numpy as np
import librosa
from typing import Tuple, Optional, List
from ai_models import ai_enhancer
from app import AudioQualityEnhancer
import warnings
warnings.filterwarnings("ignore")

class HybridAudioEnhancer:
    """æ··åˆéŸ³é¢‘å¢å¼ºå™¨ - ç»“åˆä¼ ç»Ÿä¿¡å·å¤„ç†å’ŒAIæ¨¡å‹"""
    
    def __init__(self):
        # ä¼ ç»Ÿä¿¡å·å¤„ç†å™¨
        self.traditional_enhancer = AudioQualityEnhancer()
        
        # AIå¢å¼ºå™¨
        self.ai_enhancer = ai_enhancer
        
        # å¤„ç†æ¨¡å¼
        self.processing_modes = {
            "traditional_only": "ä»…ä¼ ç»Ÿå¤„ç†",
            "ai_only": "ä»…AIå¤„ç†", 
            "ai_then_traditional": "AIä¼˜å…ˆæ··åˆ",
            "traditional_then_ai": "ä¼ ç»Ÿä¼˜å…ˆæ··åˆ",
            "parallel_blend": "å¹¶è¡Œæ··åˆ",
            "adaptive_hybrid": "è‡ªé€‚åº”æ··åˆ"
        }
        
        print("ğŸµ æ··åˆéŸ³é¢‘å¢å¼ºå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def get_available_modes(self) -> dict:
        """è·å–å¯ç”¨çš„å¤„ç†æ¨¡å¼"""
        return self.processing_modes
    
    def get_ai_models(self) -> dict:
        """è·å–å¯ç”¨çš„AIæ¨¡å‹"""
        return self.ai_enhancer.get_available_models()
    
    def load_ai_model(self, model_name: str) -> bool:
        """åŠ è½½æŒ‡å®šçš„AIæ¨¡å‹"""
        return self.ai_enhancer.download_and_load_model(model_name)
    
    def process_traditional_only(self, audio: np.ndarray, sr: int, 
                               enhancement_level: str = "medium") -> np.ndarray:
        """ä»…ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•å¤„ç†"""
        print("ğŸ”§ ä½¿ç”¨ä¼ ç»Ÿä¿¡å·å¤„ç†...")
        
        enhanced = audio.copy()
        
        if enhancement_level in ["basic", "medium", "advanced"]:
            # é™å™ª
            enhanced = self.traditional_enhancer.adaptive_noise_reduction(enhanced, sr)
            
        if enhancement_level in ["medium", "advanced"]:
            # è°æ³¢å¢å¼º
            enhanced = self.traditional_enhancer.harmonic_enhancement(enhanced, sr)
            
        if enhancement_level == "advanced":
            # åŠ¨æ€èŒƒå›´å¤„ç†
            enhanced = self.traditional_enhancer.dynamic_range_enhancement(enhanced)
            
            # ç«‹ä½“å£°å®½åº¦å¢å¼ºï¼ˆå¦‚æœæ˜¯ç«‹ä½“å£°ï¼‰
            if len(enhanced.shape) > 1 or enhanced.ndim > 1:
                enhanced = self.traditional_enhancer.stereo_width_enhancement(enhanced)
        
        return enhanced
    
    def process_ai_only(self, audio: np.ndarray, sr: int, 
                       ai_model: str = "facebook_denoiser") -> np.ndarray:
        """ä»…ä½¿ç”¨AIæ¨¡å‹å¤„ç†"""
        print(f"ğŸ¤– ä½¿ç”¨AIæ¨¡å‹å¤„ç†: {ai_model}")
        
        if not self.ai_enhancer.is_model_loaded(ai_model):
            print(f"â³ æ­£åœ¨åŠ è½½AIæ¨¡å‹: {ai_model}")
            if not self.ai_enhancer.download_and_load_model(ai_model):
                print(f"âŒ AIæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿå¤„ç†ä½œä¸ºå¤‡é€‰")
                return self.process_traditional_only(audio, sr, "medium")
        
        enhanced = self.ai_enhancer.enhance_audio(audio, sr, ai_model)
        return enhanced
    
    def process_ai_then_traditional(self, audio: np.ndarray, sr: int,
                                  ai_model: str = "facebook_denoiser",
                                  enhancement_level: str = "basic") -> np.ndarray:
        """AIä¼˜å…ˆæ··åˆï¼šå…ˆAIå¤„ç†ï¼Œå†ä¼ ç»Ÿå¢å¼º"""
        print(f"ğŸ¤–â¡ï¸ğŸ”§ AIä¼˜å…ˆæ··åˆå¤„ç†: {ai_model} + ä¼ ç»Ÿ{enhancement_level}")
        
        # ç¬¬ä¸€æ­¥ï¼šAIå¤„ç†
        ai_enhanced = self.process_ai_only(audio, sr, ai_model)
        
        # ç¬¬äºŒæ­¥ï¼šä¼ ç»Ÿå¢å¼ºï¼ˆä½¿ç”¨è¾ƒè½»çš„çº§åˆ«é¿å…è¿‡åº¦å¤„ç†ï¼‰
        final_enhanced = self.process_traditional_only(ai_enhanced, sr, enhancement_level)
        
        return final_enhanced
    
    def process_traditional_then_ai(self, audio: np.ndarray, sr: int,
                                  ai_model: str = "facebook_denoiser", 
                                  enhancement_level: str = "basic") -> np.ndarray:
        """ä¼ ç»Ÿä¼˜å…ˆæ··åˆï¼šå…ˆä¼ ç»Ÿå¤„ç†ï¼Œå†AIå¢å¼º"""
        print(f"ğŸ”§â¡ï¸ğŸ¤– ä¼ ç»Ÿä¼˜å…ˆæ··åˆå¤„ç†: ä¼ ç»Ÿ{enhancement_level} + {ai_model}")
        
        # ç¬¬ä¸€æ­¥ï¼šä¼ ç»Ÿå¤„ç†
        traditional_enhanced = self.process_traditional_only(audio, sr, enhancement_level)
        
        # ç¬¬äºŒæ­¥ï¼šAIå¢å¼º
        final_enhanced = self.process_ai_only(traditional_enhanced, sr, ai_model)
        
        return final_enhanced
    
    def process_parallel_blend(self, audio: np.ndarray, sr: int,
                             ai_model: str = "facebook_denoiser",
                             enhancement_level: str = "medium",
                             blend_ratio: float = 0.5) -> np.ndarray:
        """å¹¶è¡Œæ··åˆï¼šåŒæ—¶è¿›è¡ŒAIå’Œä¼ ç»Ÿå¤„ç†ï¼Œç„¶åæ··åˆç»“æœ"""
        print(f"ğŸ”€ å¹¶è¡Œæ··åˆå¤„ç†: {ai_model} + ä¼ ç»Ÿ{enhancement_level} (æ··åˆæ¯”ä¾‹: {blend_ratio:.1f})")
        
        # å¹¶è¡Œå¤„ç†
        ai_enhanced = self.process_ai_only(audio, sr, ai_model)
        traditional_enhanced = self.process_traditional_only(audio, sr, enhancement_level)
        
        # ç¡®ä¿ä¸¤ä¸ªç»“æœé•¿åº¦ä¸€è‡´
        min_len = min(len(ai_enhanced), len(traditional_enhanced))
        ai_enhanced = ai_enhanced[:min_len]
        traditional_enhanced = traditional_enhanced[:min_len]
        
        # æ··åˆç»“æœ
        blended = blend_ratio * ai_enhanced + (1 - blend_ratio) * traditional_enhanced
        
        return blended
    
    def process_adaptive_hybrid(self, audio: np.ndarray, sr: int,
                              ai_model: str = "facebook_denoiser") -> np.ndarray:
        """è‡ªé€‚åº”æ··åˆï¼šæ ¹æ®éŸ³é¢‘ç‰¹å¾æ™ºèƒ½é€‰æ‹©æœ€ä½³å¤„ç†æ–¹å¼"""
        print("ğŸ§  è‡ªé€‚åº”æ··åˆå¤„ç†...")
        
        # åˆ†æéŸ³é¢‘ç‰¹å¾
        audio_features = self._analyze_audio_features(audio, sr)
        
        # æ ¹æ®ç‰¹å¾é€‰æ‹©å¤„ç†ç­–ç•¥
        if audio_features["noise_level"] > 0.3:
            print("ğŸ“Š æ£€æµ‹åˆ°é«˜å™ªå£°ï¼Œä¼˜å…ˆä½¿ç”¨AIé™å™ª")
            return self.process_ai_then_traditional(audio, sr, ai_model, "basic")
        elif audio_features["dynamic_range"] < 0.2:
            print("ğŸ“Š æ£€æµ‹åˆ°åŠ¨æ€èŒƒå›´çª„ï¼Œä¼˜å…ˆä½¿ç”¨ä¼ ç»Ÿå¢å¼º")
            return self.process_traditional_then_ai(audio, sr, ai_model, "advanced")
        elif audio_features["spectral_centroid"] > 3000:
            print("ğŸ“Š æ£€æµ‹åˆ°é«˜é¢‘å†…å®¹ä¸°å¯Œï¼Œä½¿ç”¨å¹¶è¡Œæ··åˆ")
            return self.process_parallel_blend(audio, sr, ai_model, "medium", 0.6)
        else:
            print("ğŸ“Š ä½¿ç”¨å¹³è¡¡çš„æ··åˆå¤„ç†")
            return self.process_parallel_blend(audio, sr, ai_model, "medium", 0.5)
    
    def _analyze_audio_features(self, audio: np.ndarray, sr: int) -> dict:
        """åˆ†æéŸ³é¢‘ç‰¹å¾"""
        try:
            # å™ªå£°æ°´å¹³ä¼°è®¡
            stft = librosa.stft(audio)
            spectral_rolloff = librosa.feature.spectral_rolloff(S=np.abs(stft), sr=sr)
            noise_level = np.std(spectral_rolloff) / np.mean(spectral_rolloff)
            
            # åŠ¨æ€èŒƒå›´
            rms = librosa.feature.rms(y=audio)
            dynamic_range = np.std(rms) / np.mean(rms)
            
            # é¢‘è°±è´¨å¿ƒ
            spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sr))
            
            # é›¶äº¤å‰ç‡ï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰
            zcr = np.mean(librosa.feature.zero_crossing_rate(audio))
            
            return {
                "noise_level": min(noise_level, 1.0),
                "dynamic_range": min(dynamic_range, 1.0), 
                "spectral_centroid": spectral_centroid,
                "zero_crossing_rate": zcr
            }
        except Exception as e:
            print(f"éŸ³é¢‘ç‰¹å¾åˆ†æå¤±è´¥: {str(e)}")
            # è¿”å›ä¸­æ€§ç‰¹å¾
            return {
                "noise_level": 0.2,
                "dynamic_range": 0.3,
                "spectral_centroid": 2000,
                "zero_crossing_rate": 0.1
            }
    
    def _get_blend_ratio_display(self, processing_mode: str, actual_ai_used: bool, actual_traditional_used: bool, blend_ratio: float) -> str:
        """è·å–æ··åˆæ¯”ä¾‹çš„æ˜¾ç¤ºæ–‡æœ¬"""
        if processing_mode == "parallel_blend":
            return f"{blend_ratio:.1f} (AIæƒé‡)"
        elif processing_mode == "adaptive_hybrid":
            if actual_ai_used and actual_traditional_used:
                return "è‡ªé€‚åº”æ··åˆ (ç³»ç»Ÿè‡ªåŠ¨å†³å®š)"
            elif actual_ai_used:
                return "1.0 (çº¯AI)"
            else:
                return "0.0 (çº¯ä¼ ç»Ÿ)"
        elif processing_mode == "ai_then_traditional":
            return "AIâ†’ä¼ ç»Ÿ (é¡ºåºå¤„ç†)"
        elif processing_mode == "traditional_then_ai":
            return "ä¼ ç»Ÿâ†’AI (é¡ºåºå¤„ç†)"
        elif processing_mode == "ai_only":
            return "1.0 (çº¯AI)"
        elif processing_mode == "traditional_only":
            return "0.0 (çº¯ä¼ ç»Ÿ)"
        else:
            return "ä¸é€‚ç”¨"
    
    def enhance_audio(self, audio: np.ndarray, sr: int, 
                     processing_mode: str = "adaptive_hybrid",
                     ai_model: str = "facebook_denoiser",
                     enhancement_level: str = "medium",
                     blend_ratio: float = 0.5) -> Tuple[np.ndarray, dict]:
        """ä¸»è¦çš„éŸ³é¢‘å¢å¼ºæ¥å£"""
        
        # è¾“å…¥éªŒè¯
        if len(audio) == 0:
            print("âŒ è¾“å…¥éŸ³é¢‘ä¸ºç©º")
            return audio, {"error": "ç©ºéŸ³é¢‘"}
        
        if not np.isfinite(audio).all():
            print("âŒ è¾“å…¥éŸ³é¢‘åŒ…å«æ— æ•ˆæ•°å€¼")
            return audio, {"error": "æ— æ•ˆéŸ³é¢‘æ•°æ®"}
        
        # éŸ³é¢‘ç‰¹å¾åˆ†æ
        features = self._analyze_audio_features(audio, sr)
        
        try:
            # è®°å½•å®é™…ä½¿ç”¨çš„å¤„ç†æ–¹æ³•
            actual_ai_used = False
            actual_traditional_used = False
            actual_method_details = ""
            
            # æ ¹æ®æ¨¡å¼é€‰æ‹©å¤„ç†æ–¹æ³•
            if processing_mode == "traditional_only":
                enhanced = self.process_traditional_only(audio, sr, enhancement_level)
                method_used = f"ä¼ ç»Ÿå¤„ç† ({enhancement_level})"
                actual_traditional_used = True
                actual_method_details = f"ä»…ä¼ ç»Ÿä¿¡å·å¤„ç†ï¼Œçº§åˆ«ï¼š{enhancement_level}"
                
            elif processing_mode == "ai_only":
                enhanced = self.process_ai_only(audio, sr, ai_model)
                method_used = f"AIå¤„ç† ({ai_model})"
                actual_ai_used = True
                actual_method_details = f"ä»…AIæ¨¡å‹å¤„ç†ï¼š{ai_model}"
                
            elif processing_mode == "ai_then_traditional":
                enhanced = self.process_ai_then_traditional(audio, sr, ai_model, enhancement_level)
                method_used = f"AIâ†’ä¼ ç»Ÿ ({ai_model} + {enhancement_level})"
                actual_ai_used = True
                actual_traditional_used = True
                actual_method_details = f"AIä¼˜å…ˆï¼š{ai_model} â†’ ä¼ ç»Ÿ{enhancement_level}"
                
            elif processing_mode == "traditional_then_ai":
                enhanced = self.process_traditional_then_ai(audio, sr, ai_model, enhancement_level)
                method_used = f"ä¼ ç»Ÿâ†’AI ({enhancement_level} + {ai_model})"
                actual_ai_used = True
                actual_traditional_used = True
                actual_method_details = f"ä¼ ç»Ÿä¼˜å…ˆï¼š{enhancement_level} â†’ {ai_model}"
                
            elif processing_mode == "parallel_blend":
                enhanced = self.process_parallel_blend(audio, sr, ai_model, enhancement_level, blend_ratio)
                method_used = f"å¹¶è¡Œæ··åˆ ({ai_model} + {enhancement_level}, æ¯”ä¾‹:{blend_ratio:.1f})"
                actual_ai_used = True
                actual_traditional_used = True
                actual_method_details = f"å¹¶è¡Œæ··åˆï¼š{ai_model}({blend_ratio:.1f}) + ä¼ ç»Ÿ{enhancement_level}({1-blend_ratio:.1f})"
                
            elif processing_mode == "adaptive_hybrid":
                enhanced = self.process_adaptive_hybrid(audio, sr, ai_model)
                method_used = "è‡ªé€‚åº”æ··åˆ"
                # è‡ªé€‚åº”æ¨¡å¼ä¼šæ ¹æ®éŸ³é¢‘ç‰¹å¾å†³å®šæ˜¯å¦ä½¿ç”¨AI
                if features["noise_level"] > 0.3 or features["dynamic_range"] < 0.2 or features["spectral_centroid"] > 3000:
                    actual_ai_used = True
                    actual_traditional_used = True
                    actual_method_details = f"è‡ªé€‚åº”é€‰æ‹©ï¼š{ai_model} + ä¼ ç»Ÿå¤„ç†"
                else:
                    actual_ai_used = True
                    actual_traditional_used = True
                    actual_method_details = f"è‡ªé€‚åº”é€‰æ‹©ï¼šå¹³è¡¡æ··åˆ {ai_model} + ä¼ ç»Ÿå¤„ç†"
                
            else:
                print(f"âŒ æœªçŸ¥çš„å¤„ç†æ¨¡å¼: {processing_mode}")
                enhanced = self.process_traditional_only(audio, sr, "medium")
                method_used = "ä¼ ç»Ÿå¤„ç† (é»˜è®¤)"
                actual_traditional_used = True
                actual_method_details = "é»˜è®¤ä¼ ç»Ÿå¤„ç†"
            
            # æœ€ç»ˆæ£€æŸ¥å’Œæ ‡å‡†åŒ–
            if not np.isfinite(enhanced).all():
                print("âš ï¸ å¤„ç†ç»“æœåŒ…å«æ— æ•ˆæ•°å€¼ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘")
                enhanced = audio
                method_used += " (å¤±è´¥ï¼Œè¿”å›åŸå§‹)"
            
            # æ ‡å‡†åŒ–åˆ°åˆç†èŒƒå›´
            if np.max(np.abs(enhanced)) > 0:
                enhanced = enhanced / np.max(np.abs(enhanced)) * 0.95
            
            # è¿”å›ç»“æœå’Œå…ƒæ•°æ®
            metadata = {
                "method_used": method_used,
                "original_features": features,
                "processing_mode": processing_mode,
                "ai_model": ai_model if actual_ai_used else None,
                "ai_model_used": ai_model if actual_ai_used else "æœªä½¿ç”¨",
                "traditional_used": actual_traditional_used,
                "enhancement_level": enhancement_level,
                "actual_method_details": actual_method_details,
                "blend_ratio_used": blend_ratio if processing_mode == "parallel_blend" else None,
                "blend_ratio_display": self._get_blend_ratio_display(processing_mode, actual_ai_used, actual_traditional_used, blend_ratio),
                "success": True
            }
            
            print(f"âœ… éŸ³é¢‘å¢å¼ºå®Œæˆ: {method_used}")
            return enhanced, metadata
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘å¢å¼ºå¤±è´¥: {str(e)}")
            return audio, {"error": str(e), "success": False}

# å…¨å±€æ··åˆå¢å¼ºå™¨å®ä¾‹
hybrid_enhancer = HybridAudioEnhancer() 